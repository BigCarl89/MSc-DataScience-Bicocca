{"cells":[{"cell_type":"markdown","id":"b6c56b96","metadata":{"id":"b6c56b96"},"source":["# Demo"]},{"cell_type":"code","execution_count":null,"id":"1d95025a","metadata":{"id":"1d95025a"},"outputs":[],"source":["import os\n","import time\n","import sklearn\n","import joblib\n","import sounddevice as sd\n","import numpy as np\n","import librosa\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2 as cv\n","\n","import keras\n","from keras.preprocessing.image import img_to_array\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.preprocessing import image as kimage\n","from tensorflow import keras\n","from keras_vggface.vggface import VGGFace\n","from keras_vggface.utils import preprocess_input\n","\n","from sklearn.neighbors import KDTree"]},{"cell_type":"markdown","source":["## Audio"],"metadata":{"id":"HwUfP061FxBd"},"id":"HwUfP061FxBd"},{"cell_type":"code","execution_count":null,"id":"5f458f59","metadata":{"id":"5f458f59"},"outputs":[],"source":["names = [\"Alberto\", \"Alice\", \"Davide\"]"]},{"cell_type":"code","execution_count":null,"id":"fb1bed1d","metadata":{"id":"fb1bed1d"},"outputs":[],"source":["audiorecog_model = keras.models.load_model('mod_voce.h5')"]},{"cell_type":"code","execution_count":null,"id":"7c0b2bc9","metadata":{"id":"7c0b2bc9"},"outputs":[],"source":["def mfcc(input, rate=44100, sampling=1):\n","    signal = input[::sampling]\n","    mfcc = librosa.feature.mfcc(y=signal*1.0, sr=int(rate/sampling))\n","    return mfcc"]},{"cell_type":"code","execution_count":null,"id":"cd59319a","metadata":{"id":"cd59319a"},"outputs":[],"source":["def audio_prediction(duration, rec_rate=44100):\n","    if duration%2!=0:\n","        duration +=1\n","    for i in range(int(duration/2)):\n","        track = sd.rec(int(2 * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n","        prediction = np.round(audiorecog_model.predict(mfcc(track.reshape(-1)).reshape(-1,20,173,1)), 3)\n","        print('Registrazione {}: {}'.format(i+1, names[np.argmax(prediction)]))\n","        print('---------------------------------')\n","        print(pd.DataFrame({'Nome':names, 'Probabilità':prediction[0]}))\n","        print('---------------------------------')\n","        print('')"]},{"cell_type":"code","execution_count":null,"id":"34903332","metadata":{"id":"34903332"},"outputs":[],"source":["audio_prediction(30)"]},{"cell_type":"markdown","source":["## Image"],"metadata":{"id":"fHEitJ5uFzvE"},"id":"fHEitJ5uFzvE"},{"cell_type":"code","execution_count":null,"id":"92faa4c7","metadata":{"id":"92faa4c7"},"outputs":[],"source":["imagerecog_mod=keras.models.load_model('mod_img.h5')"]},{"cell_type":"code","source":["def image_acquisition(num_images, model):\n","    face_detector = cv.CascadeClassifier(cv.data.haarcascades+'haarcascade_frontalface_default.xml')\n","    i = 0\n","    for i in range(num_images):\n","        cap = cv.VideoCapture(0)\n","        time.sleep(2)\n","        result, img = cap.read()\n","        faces = face_detector.detectMultiScale(img, minNeighbors=10, minSize=(50,50))\n","        for (x,y,w,h) in faces:\n","            face = img[y:y+h,x:x+h,:]\n","            img_pixels = cv.resize(face, (224, 224)) \n","            img_pixels = img_to_array(img_pixels)\n","            img_pixels = np.expand_dims(img_pixels, axis = 0)\n","            img_pixels = preprocess_input(img_pixels)\n","            pred=model.predict(img_pixels)\n","            print(\"Foto\",i+1,':', names[np.argmax(pred)])\n","            print('---------------------------------')\n","            plt.subplot(1,2,1); plt.imshow(img[:,:,-1::-1]); plt.title(\"Immagine completa:\")\n","            plt.subplot(1,2,2); plt.imshow(face[:,:,-1::-1]); plt.title(\"Volto:\"); plt.show()\n","            print(pd.DataFrame({'Nome': names, 'Probabilità': np.round(pred, 4)[0]}))\n","            print('---------------------------------')\n","            print('')\n","            i=i+1\n","    cap.release()"],"metadata":{"id":"v3KyPz-VF9J2"},"id":"v3KyPz-VF9J2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_acquisition(4, imagerecog_mod)"],"metadata":{"id":"R-pJVySYGaC-"},"id":"R-pJVySYGaC-","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Retrieval"],"metadata":{"id":"Np_o-ITyIRAE"},"id":"Np_o-ITyIRAE"},{"cell_type":"code","source":["face_detector = cv.CascadeClassifier(cv.data.haarcascades +'haarcascade_frontalface_default.xml')\n","\n","def create_new_path(start, paths):\n","    new_paths = []\n","    for i in paths:\n","        end = i.split('content')[1]\n","        end = end.replace('/', '\\\\')\n","        path = start + end\n","        new_paths.append(path)\n","    return new_paths\n","\n","def neural_features_(img):\n","    global roi_color \n","    x = np.asarray(img)\n","    detector = cv.CascadeClassifier(cv.data.haarcascades +'haarcascade_frontalface_default.xml')\n","    results = detector.detectMultiScale(x)\n","    for (x, y, w, h) in results:\n","        cv.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","        roi_color = img[y:y + h, x:x + w]\n","    x = cv.resize(roi_color, (224,224))\n","    x = x[:,:,-1::-1].astype('float64')\n","    x = preprocess_input(x, version = 2) \n","    x = np.expand_dims(x, axis=0)\n","    f = resnet.predict(x)\n","    return f.flatten()"],"metadata":{"id":"gaK50-JTISPK"},"id":"gaK50-JTISPK","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Caricamento del modello e delle feature estratte dalle immagini del database.  \n","Creazione dell'albero e modifica ai path per raggiungere le immagini nella nuova directory."],"metadata":{"id":"ZUYxE4weJYkU"},"id":"ZUYxE4weJYkU"},{"cell_type":"code","source":["resnet = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n","\n","paths, features = joblib.load('modello_definitivo.joblib')\n","\n","tree = KDTree(features) \n","\n","start = 'data\\\\thumbnails_features_deduped_publish'\n","new_paths = create_new_path(start=start, paths = paths)"],"metadata":{"id":"cskFg1XbJEdJ"},"id":"cskFg1XbJEdJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Acquisizione fotografia con ritaglio del volto."],"metadata":{"id":"M2XH6h6KJbDn"},"id":"M2XH6h6KJbDn"},{"cell_type":"code","source":["cap = cv.VideoCapture(0)\n","result, img = cap.read()\n","cap.release()\n","\n","faces = face_detector.detectMultiScale(img)\n","for (x,y,w,h) in faces:\n","    face = img[y:y+h,x:x+h,:]\n","    \n","plt.imshow(face[:,:,-1::-1]), plt.show()"],"metadata":{"id":"KANwhjigJEgS"},"id":"KANwhjigJEgS","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Estrazione feature dal volto e ricerca della query nel db."],"metadata":{"id":"0LNmltnlJb_g"},"id":"0LNmltnlJb_g"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e45f5aa"},"outputs":[],"source":["query_features = neural_features_(face)\n","query_features = np.expand_dims(query_features, axis=0)"],"id":"9e45f5aa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4d820aeb"},"outputs":[],"source":["start = time.time()\n","dist, ind = tree.query(query_features, k=10, dualtree=True)\n","print(time.time()-start)"],"id":"4d820aeb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7f468f49"},"outputs":[],"source":["fig = plt.figure(figsize=(20,11))\n","for i in range(10):\n","    sub = fig.add_subplot(2,5,i+1)\n","    sub.title.set_text(new_paths[ind[0][i]].split('\\\\')[3])\n","    sub.title.set_size(20)\n","    sub.text(10, -20, (\"distance:\" + str(round(dist[0][i],3))), fontsize=15)\n","    fig.suptitle('10 volti più simili con VGGFace-resnet',size=25)\n","    sub.imshow(kimage.load_img(new_paths[ind[0][i]]), interpolation='bilinear')"],"id":"7f468f49"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"Demo.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}